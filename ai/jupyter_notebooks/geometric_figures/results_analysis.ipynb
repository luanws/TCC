{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from termcolor import colored\n",
    "\n",
    "from src.models.model_result import ModelResult\n",
    "from src.services.result import get_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (512, 512)\n",
    "MODEL_RESULTS_PATH = 'data/results.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results: List[ModelResult] = get_model_results(MODEL_RESULTS_PATH)\n",
    "model_names = list(set([model_result['model_name'] for model_result in model_results]))\n",
    "model_names.sort(key=lambda x: [model_result['model_name'] for model_result in model_results].index(x))\n",
    "print(f'{colored(\"Model names:\", \"cyan\")} {\", \".join(model_names)}')\n",
    "\n",
    "dataset_versions = list(set([model_result['dataset_version'] for model_result in model_results]))\n",
    "dataset_versions.sort()\n",
    "print(f'{colored(\"Dataset versions:\", \"cyan\")} {\", \".join(dataset_versions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_version in dataset_versions:\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    for model_name in model_names:\n",
    "        accuracy_list = [m['accuracy'] for m in model_results if m['model_name'] == model_name and m['dataset_version'] == dataset_version]\n",
    "        if len(accuracy_list) == 0:\n",
    "            continue\n",
    "        mean = np.mean(accuracy_list)\n",
    "        plt.title(f'Acurácia média para o dataset {dataset_version}')\n",
    "        plt.bar(model_name, mean)\n",
    "        plt.text(model_name, mean, f'{mean:.2%}', ha='center', va='bottom')\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        plt.ylim(0, 1.1)\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_version in dataset_versions:\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    for model_name in model_names:\n",
    "        accuracy_list = [m['accuracy'] for m in model_results if m['model_name'] == model_name and m['dataset_version'] == dataset_version]\n",
    "        if len(accuracy_list) == 0:\n",
    "            continue\n",
    "        max_accuracy = np.max(accuracy_list)\n",
    "        plt.title(f'Acurácia máxima por modelo para o dataset {dataset_version}')\n",
    "        plt.bar(model_name, max_accuracy)\n",
    "        plt.text(model_name, max_accuracy, f'{max_accuracy:.2%}', ha='center', va='bottom')\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        plt.ylim(0, 1.1)\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_color(accuracy: float) -> str:\n",
    "    colors = [\n",
    "        '#d62728',\n",
    "        '#d62728',\n",
    "        '#d62728',\n",
    "\n",
    "        '#ff7f0e',\n",
    "        '#ff7f0e',\n",
    "\n",
    "        '#bcbd22',\n",
    "        '#bcbd22',\n",
    "\n",
    "        '#2ca02c',\n",
    "    ]\n",
    "    linspace = np.linspace(0, 1, len(colors) + 1)\n",
    "    index = np.where(accuracy > linspace)[0][-1]\n",
    "    return colors[index]\n",
    "\n",
    "\n",
    "for dataset_version in dataset_versions:\n",
    "    fig, axs = plt.subplots(len(model_names), 1, figsize=(18, 3 * len(model_names)))\n",
    "    if len(model_names) == 1:\n",
    "        axs = [axs]\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        accuracy_list = [m['accuracy'] for m in model_results if m['model_name']\n",
    "                         == model_name and m['dataset_version'] == dataset_version]\n",
    "        if len(accuracy_list) == 0:\n",
    "            continue\n",
    "        axs[i].set_title(f'Acurácias do modelo {model_name} para o dataset {dataset_version}')\n",
    "        axs[i].set_xticks(range(len(accuracy_list)))\n",
    "        for j, accuracy in enumerate(accuracy_list):\n",
    "            axs[i].bar(f'{j + 1}', accuracy, color=get_accuracy_color(accuracy))\n",
    "            axs[i].text(j, accuracy, f'{accuracy:.2%}', ha='center', va='bottom')\n",
    "        axs[i].set_yticks([])\n",
    "        axs[i].set_ylim(0, 1.1)\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
