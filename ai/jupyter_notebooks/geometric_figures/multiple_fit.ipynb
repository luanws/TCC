{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, f1_score,\n",
    "                             precision_score, recall_score)\n",
    "from tensorflow import keras\n",
    "from termcolor import colored\n",
    "\n",
    "from src.models.geometric_figure import GeometricFigure\n",
    "from src.services.geometric_figure import (get_geometric_figures,\n",
    "                                           get_train_test_validation_split)\n",
    "from src.services.result import save_model_results\n",
    "from src.utils.files import create_directory_if_not_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (128, 128)\n",
    "TEST_RATIO = 0.2\n",
    "VALIDATION_RATIO = 0.1\n",
    "DATA_VERSIONS = ['2023-04-24']\n",
    "MODEL_RESULTS_PATH = 'data/results.json'\n",
    "NUMBER_OF_REPETITIONS = 5\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_models: Dict[str, keras.Model] = {\n",
    "    'P1': lambda: keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(6, activation='softmax')\n",
    "    ]),\n",
    "    'P2': lambda: keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(6, activation='softmax')\n",
    "    ]),\n",
    "    'CNN1': lambda: keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1)),\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((4, 4)),\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((4, 4)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(8, activation='relu'),\n",
    "        keras.layers.Dense(6, activation='softmax')\n",
    "    ]),\n",
    "    'CNN2': lambda: keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1)),\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((4, 4)),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((4, 4)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(8, activation='relu'),\n",
    "        keras.layers.Dense(6, activation='softmax')\n",
    "    ]),\n",
    "    # 'CNN3': lambda: keras.Sequential([\n",
    "    #     keras.layers.InputLayer(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1)),\n",
    "    #     keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    #     keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    #     keras.layers.MaxPooling2D((2, 2)),\n",
    "    #     keras.layers.Dropout(0.25),\n",
    "    #     keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    #     keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    #     keras.layers.MaxPooling2D((2, 2)),\n",
    "    #     keras.layers.Dropout(0.25),\n",
    "    #     keras.layers.Flatten(),\n",
    "    #     keras.layers.Dense(256, activation='relu'),\n",
    "    #     keras.layers.Dropout(0.5),\n",
    "    #     keras.layers.Dense(6, activation='softmax')\n",
    "    # ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometric_figures_data_versions_dict: Dict[str, List[GeometricFigure]] = {\n",
    "    version: get_geometric_figures(f'data/{version}', IMAGE_SIZE) for version in DATA_VERSIONS\n",
    "}\n",
    "for version, geometric_figures in geometric_figures_data_versions_dict.items():\n",
    "    print(f'Loaded {colored(len(geometric_figures), \"green\")} geometric figures for version {colored(version, \"green\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(y_test: np.ndarray, y_test_predicted: np.ndarray, model_name: str, version: str, datetime_now: str):\n",
    "    accuracy = accuracy_score(y_test, y_test_predicted)\n",
    "    precision = precision_score(y_test, y_test_predicted, average='weighted')\n",
    "    recall = recall_score(y_test, y_test_predicted, average='weighted')\n",
    "    f1 = f1_score(y_test, y_test_predicted, average='weighted')\n",
    "\n",
    "    print(f'Acurácia: {accuracy:.2%}')\n",
    "    print(f'Precisão: {precision:.2%}')\n",
    "    print(f'Sensibilidade: {recall:.2%}')\n",
    "    print(f'F1: {f1:.2%}')\n",
    "\n",
    "    metrics_dict = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    path_metrics = f'data/metrics/{version}/{model_name}/{datetime_now}/metrics.json'\n",
    "    create_directory_if_not_exists(path_metrics)\n",
    "    with open(path_metrics, 'w') as file:\n",
    "        content = json.dumps(metrics_dict, indent=4)\n",
    "        file.write(content)\n",
    "\n",
    "    confusion = confusion_matrix(y_test, y_test_predicted)\n",
    "    labels = ['circle', 'square', 'triangle', 'failed circle', 'failed square', 'failed triangle']\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'Matriz de confusão - {version}')\n",
    "    plt.xlabel('Classe Prevista')\n",
    "    plt.ylabel('Classe Verdadeira')\n",
    "    path = f'data/metrics/{version}/{model_name}/{datetime_now}/confusion_matrix.svg'\n",
    "    create_directory_if_not_exists(path)\n",
    "    fig.savefig(path, bbox_inches='tight', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_version in DATA_VERSIONS:\n",
    "    geometric_figures = geometric_figures_data_versions_dict[data_version]\n",
    "    for i in range(NUMBER_OF_REPETITIONS):\n",
    "        x_train, y_train, x_test, y_test, x_validation, y_validation = get_train_test_validation_split(\n",
    "            geometric_figures,\n",
    "            test_ratio=TEST_RATIO,\n",
    "            validation_ratio=VALIDATION_RATIO,\n",
    "            shuffle=True\n",
    "        )\n",
    "        # data_generator = keras.preprocessing.image.ImageDataGenerator(\n",
    "        #     rotation_range=360,\n",
    "        #     width_shift_range=0.1,\n",
    "        #     height_shift_range=0.1,\n",
    "        #     horizontal_flip=True,\n",
    "        #     vertical_flip=True,\n",
    "        # )\n",
    "        # train_generator = data_generator.flow(x_train, y_train)\n",
    "        for name, create_model in ai_models.items():\n",
    "            model = create_model()\n",
    "            model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "            print(f'Training {name}')\n",
    "            # model.fit(train_generator, epochs=EPOCHS, validation_data=(x_validation, y_validation))\n",
    "            model.fit(x_train, y_train, epochs=EPOCHS, validation_data=(x_validation, y_validation))\n",
    "            print(f'Evaluating {name}')\n",
    "            loss, accuracy = model.evaluate(x_test, y_test)\n",
    "            print(f'Saving {name}')\n",
    "            datetime_now = datetime.now().strftime('%Y-%m-%d %H-%M-%S')\n",
    "            model.save(f'data/models/{data_version}/{name}/{datetime_now}.h5')\n",
    "            save_model_results(name, accuracy, datetime_now, data_version, MODEL_RESULTS_PATH)\n",
    "            predictions = model.predict(x_test)\n",
    "            y_test_predicted = tf.argmax(predictions, axis=1).numpy()\n",
    "            save_metrics(y_test, y_test_predicted, name, data_version, datetime_now)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
